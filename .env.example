# AgentForge Environment Variables
# Copy this file to .env and fill in your values

# ===================
# LLM CONFIGURATION
# ===================
# You need at least one LLM provider configured for the agents to work

# OpenAI API Key (for GPT models)
OPENAI_API_KEY=your_openai_api_key_here

# Anthropic API Key (for Claude models)
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# Ollama Configuration (for local/free models)
# Base URL for Ollama server (default: http://localhost:11434)
OLLAMA_BASE_URL=http://localhost:11434
# Set to true to use Ollama as default LLM provider
USE_OLLAMA=false

# Other Local LLM Providers
# LM Studio (OpenAI-compatible API)
LMSTUDIO_BASE_URL=http://localhost:1234/v1
# LocalAI (OpenAI-compatible API)
LOCALAI_BASE_URL=http://localhost:8080

# ===================
# OPTIONAL SETTINGS
# ===================

# Application Environment
ENV=production
DEBUG=False
LOG_LEVEL=INFO

# CORS Origins (comma-separated, for frontend access)
CORS_ORIGINS=http://localhost:3000,http://localhost:5000,http://localhost:5173,http://127.0.0.1:3000,http://127.0.0.1:5000,http://127.0.0.1:5173

# Frontend API URL
VITE_API_URL=http://localhost:8000
